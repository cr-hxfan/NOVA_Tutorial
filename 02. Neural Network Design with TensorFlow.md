# Neural Network Design with TensorFlow



本教程将介绍VGG网络的基本概念，SSD目标检测框架的工作原理，并且动手实现一个完整的CNN骨干（backbone）网络。



本教程安排如下：

- [1. 实验原理](#1-实验原理)
    - [1.1 VGG网络介绍](#11-vgg网络介绍)
    - [1.2 SSD目标检测框架概述](#12-ssd目标检测框架概述)
- [2. 练习](#2-练习)
    - [2.1 构建基于类VGG结构的SSD神经网络](#21-构建基于类VGG结构的SSD神经网络)
    - [2.2 网络训练](#22-网络训练)







预期目标：
1. 了解VGG网络的结构和特点，以及主流目标检测算法SSD的基本原理。
2. 
3. 熟练掌握使用TensorFlow进行神经网络搭建的方法。







## 1. 实验原理
### 1.1 VGG网络介绍

[VGG](https://arxiv.org/abs/1409.1556)是由牛津大学Visual Geometry Group提出的。一个标准的VGG网络结构如下图所示，在VGG中，所有卷积层的卷积核大小均为3×3，池化核大小均为2×2。

![VGG](https://i.loli.net/2019/07/04/5d1d6ff94747420902.png)

- 小卷积核是VGG的一个重要特征。VGG通过堆叠使用多个卷积核为3×3的卷积层来实现5×5或7×7这样具有较大卷积核的卷积层所能达到的感受野，这样一方面可以有效减少参数，另一方面则是增加了更多的非线性映射，能够增强网络的拟合能力。

- 通道数更多也是VGG一个明显的特征。VGG网络第一层的通道数为64，之后每层翻倍，最多到512个通道，通道数的增加，模型可以表达更丰富的特征信息。


VGGNet探索了卷积神经网络的深度与其性能之间的关系，成功地构筑了16~19层深的卷积神经网络，证明了增加网络的深度能够在一定程度上影响网络最终的性能，使错误率大幅下降，同时拓展性又很强，迁移到其它图片数据上的泛化性也非常好。因此，VGG常被用来进行图像特征的提取，作为其他深度学习模型的主干（backbone）网络。




### 1.2 SSD目标检测框架概述

由于图像特征提取网络所取得的进步，基于图像的任务（如目标检测）也取得了重要的进展。



主流的目标检测算法分为两种类型：two-stage和one-stage两种检测方法。



two-stage检测分为两步，首先推断出目标候选框（Region proposal），表示可能有物体的区域，之后再提取出候选框内的特征，进行具体类别的分类以及更准确的定位（回归）。



相比于two-stage检测分两步走的方法，one-stage检测方法仅需要将图片送入网络一次就可以完成推断，在不损失过多精度的情况下大幅提升了检测速度，更加适用于工业级应用。



本实验以经典的one-stage检测方法Single-Shot Multibox Detector（SSD）为例进行。SSD的具体原理可以参考[原论文](https://arxiv.org/abs/1512.02325)。



标准的SSD网络主要由主干网络（特征提取网络）和多尺度的检测分支两部分组成。
![ssd.jpg](http://images2015.cnblogs.com/blog/1005315/201703/1005315-20170321214539611-212225585.png)

SSD网络使用VGG-16完成图像特征的提取。在VGG中，随着层数的加深，得到的特征图尺寸越来越小。不同层的特征图能代表不同尺度下的语义信息，浅层特征图包含更多局部特征，更偏向于对于细节的描述，适合小尺度目标的检测。深层的特征捕捉更抽象化的全局信息，适合对大尺度目标的检测。



同时，SSD使用多个检测分支对不同尺度的特征图进行预测。每个检测分支负责预测该尺度上目标框的类别和位置信息。检测分支采用Anchors实现预测，Anchor包含了多个预定义的基准检测框，SSD解决的是如何对于基准框进行微调来实现最终的高精度检测结果。



关于SSD中Anchors的概念可以参考下图：

![example.PNG](https://i.loli.net/2018/11/29/5bff52b8e1cd7.png)



上图显示了SSD检测图中的猫和狗的过程，其中蓝色代表猫，红色代表狗。由于猫和狗在图中的尺寸不同，SSD中使用不同的分支完成对于猫和狗的检测。



（b）图代表8x8的特征图对应的分支，（c）图代表4x4的特征图分支。具体来说，（b）层位于浅层，对应于猫的检测，（c）层位于深层，对应于狗的检测。（b）、（c）图中的虚线框代表Anchor的基准框，基准框有着不同的尺度和长宽比，以保证对于各种尺寸和形状物体的匹配。基于匹配的Anchor，SSD通过计算每个Anchor负责区域的位置偏差量Δ(cx, cy, w, h)和对应的类别置信度(c_1, c_2, ..., c_p)，最终实现对于物体的检测。



## 2. 练习

本教程的实验分为两部分，第一部分为SSD框架下模型主干网络的搭建，第二部分为简单的模型训练以及实际应用场景下模型部署前的处理工作。其中，模型的后处理过程在此实验中暂不展开，我们将在《Custom Object Detection Model Deployment》中进行详细的介绍和实践。



实验所需的所有文件都被提前放置在`./lab_02`路径下。



### 2.1 构建基于类VGG结构的SSD神经网络

在《introduction to TensorFlow》中，我们已经掌握了`slim`模块的用法。因此，本次实验的内容是使用`slim`搭建一个SSD网络，其结构如下图所示：
![SSD](https://i.loli.net/2019/07/22/5d3584edddf9e49336.png)

我们使用bloc,3，4，block7，block8，block9，block10生成的feature map进行预测，因此我们建议用户在定义模型时将对应层的输出标记为我们需要的block3，4，7，8，9，10。



实验要求：
1. 在`/lab_02/nets/ssd_KYnet_v3_6b.py`文件中第440行起，使用`slim`复现上图的网络结构。

2. 按要求正确命名对应输出层。

3. 在`/lab_02/nets/ssd_KYnet_v3_6b.py`文件中第536行起，定义模型所使用的卷积和池化操作的关键参数。
   - 所有计算操作的padding为`SAME`，数据格式`data_format`为`NHWC`

   - 所有卷积核大小为3×3，weight_regularizer使用`caffe_scope.conv_weights_init()`，biases_initializer使用` caffe_scope.conv_biases_init()`，激活函数使用`tf.nn.reLu`

   - 池化方式为最大池化，且池化核为2×2



### 2.2 网络训练

在完成了目标模型的搭建后，我们需要对该模型进行训练。本实验的目的在于获得最终的`inference_model`和`post_param`两个文件。

> 注意：本实验建议在docker中进行。



在`./lab_02`中，我们提供了`tf_convert_data.py`, `train_ssd_network.py`, `post_gen.py`和`export_inference_graph.py`四个python文件来辅助用户完成这个小实验。这四个文件的作用分别是：

- `tf_convert_data.py`：将训练数据转化为TFrecord的格式

- `train_ssd_network.py`：训练模型

- `post_gen.py`：根据模型导出预设的anchor参数

- `export_inference_graph.py`：去除与推演无关的节点，保留核心的运算节点

1）我们提供了19张图片作为训练数据，以帮助用户了解算法模型的训练过程。数据的标注方式如下：

```

[图像名] [物体数量] [物体1]:[物体1的label_id] [2(预定义字段)] [左上角x坐标] [y坐标] [右下角x坐标] [y坐标]

```

首先，我们需要完成数据格式的转换。

```python

python tf_convert_data.py                   #调用py文件
       
       --dataset_name=test_release          #数据库名称
    
       --dataset_dir=./imagetxt/            #输入路径
    
       --output_dir=./data_conversion       #输出路径
    
       --shuffle=True
        
```



2）之后便可进行网络的训练，在训练过程中我们将得到该模型的checkpoint文件。

```shell


mkdir ./logs_test/

cp ./data_conversion/test_release.json ./logs_test/image.json

cp ./data_conversion/test_release.INFO ./logs_test/image.INFO



python -u train_ssd_network.py \

	--gpus=0 \                            #通过指定id来使用特定的GPU进行计算

	--num_clones=1 \                      #训练所使用的GPU数量

	--train_dir=./logs_test/ \            #指定保留checkpoint文件的路径

	--dataset_dir=./data_conversion \        

	--dataset_name=test_release \         #明确TF格式数据库的名称

	--dataset_split_name=train \

	--model_name=ssd_KYnet_v3_6b \        #模型文件

	--save_summaries_secs=600 \

	--save_interval_secs=1200 \           #存储模型文件的间隔时间

	--weight_decay=0.00001 \              #正则项系数

	--optimizer=adam \

	--learning_rate=0.005 \               #起始学习率

	--learning_rate_decay_factor=0.95 \   #学习率衰减因子

	--batch_size=20  \

	--debug_type=True \

	--num_epochs_per_decay=100.0          #调整学习率变化的步数间隔

```



3）在完成训练后，可以通过如下方式调用`post_gen.py`来导出我们模型预设的anchor参数。这样做的目的是为了减少模型的复杂度：在实际应用时时，仅将模型的核心运算部分部署在加速器上，将于推演无关的部分从模型中剥离出来在CPU上实现，这样可以有效地提高推演的速度。

```python

python post_gen.py \        #调用py文件
       
       ssd_KYnet_v3_6b \    #声明网络结构
    
       ./post_param         #输出路径
        
```



4） 最后，将模型导出。这一步的主要目的在于固定输入数据的大小和格式。由于模型在训练结束之后仍然保留着训练的状态，比如数据的输入仍然为一个队列，输入的`shape`的`batch_size`仍然为一个比较大的值。因此，在使用`compiler`进行模型编译之前，我们需要对模型进行一些预处理，使其能够被`compiler`正确编译。

```shell

python export_inference_graph.py \  #调用py文件
       
       ssd_KYnet_v3_6b \
       
       ./logs_test \                #输入路径
       
       ./inference_model            #输出路径
       
```

