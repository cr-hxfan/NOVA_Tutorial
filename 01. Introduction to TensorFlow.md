# Introduction to TensorFlow



本实验对TensorFlow和卷积神经网络做了非常简洁的介绍，从卷积神经网络的基本组成讲起，再到具体计算操作在TensorFlow中的实现，最后基于这些知识动手搭建一个简单的网络。

> 注意，本实验部分内容建议在docker中进行。



本次教程安排如下：




- [1. CNN基础](#1-CNN基础)
    - [1.1 TensorFlow介绍](#11-tensorflow介绍)
    - [1.2 卷积神经网络基础](#12-卷积神经网络基础)
        - [1.2.1 卷积](#121-卷积)
        - [1.2.2 池化](#122-池化)
        - [1.2.3 激活函数](#123-激活函数)
        - [1.2.4 全连接](#124-全连接)
    - [1.3 实现一个计算层](#13-实现一个计算层)
- [2 CIFAR-10介绍](#2-cifar-10介绍)
    - [2.1 数据转换](#21-数据转换)
    - [2.2 模型介绍](#22-模型介绍)
        - [2.2.1 `slim`库介绍](#221-slim库介绍)
        - [2.2.2 常见的`slim` API](#222-常见的slim-api)
    - [2.3 数据预处理与网络模型训练](#23-数据预处理与网络模型训练)
        - [2.3.1 数据预处理](#231-数据预处理)
        - [2.3.2 网络模型训练](#232-网络模型训练)
- [3. 练习](#3-练习)
    - [3.1 模型训练与验证](#31-模型训练与验证)
        - [3.1.1 数据转换](#311-数据转换)
        - [3.1.2 模型训练](#312-模型训练)
        - [3.1.3 模型验证](#313-模型验证)
    - [3.2 搭建一个神经网络并进行训练](#32-搭建一个神经网络并进行训练)







预期目标：
1. 了解TensorFlow的基本组成元素，掌握卷积神经网络的主要组成部分，同时了解卷积神经网络中重要计算操作的原理；

2. 掌握TensorFlow中对应API的使用方法。

3. 了解TensorFlow标准格式`TFrecord`的转换方法，以及常用的数据预处理方法。

4. 掌握`slim`模块的使用方法，并能够自主搭建一个基于CIFAR10数据集的神经网络。







## 1. CNN基础

### 1.1 TensorFlow介绍

TensorFlow是一个面向机器学习的端到端开源平台，它拥有灵活而全面的开发工具、社区资源和生态系统，用户通过Tensorflow可以轻松地开发机器学习的应用。



TensorFlow的三大构成要素为：**数据流图**，**张量**，**会话**



其中，TensorFlow的核心为**数据流图（Data Flow Graph）**。顾名思义，在Tensorflow中，数据从某个节点流向下一个节点，某个计算节点的输出是下一个计算节点的输入（或部分输入）。



**数据流图**由**节点（Node）** 和 **边（Edge）** 两个基本元素组成。
- **节点**表示对数据进行的数学操作（也称为**OP**），也可以用来表示数据的起点和终点。
- **边**则表示节点之间数据的传递关系



而**边**上所传递的数据，，我们称之为**张量（Tensor）**，用于图像的神经网络中，常用的图像数据表示形式为：`batch*height*width*channel`。

- `batch`表示每次迭代中所使用的样本数量
- `height`和`weight`表示个样本的尺寸大小
- `channel`表示输入图像或特征图的通道数，比如一张彩色图片有R、G、B三个通道



因此大家就可以非常轻易地理解TensorFlow这个名称所代表的含义：数据在节点之间的流动。



而由节点和边所组成的数据流图只定义了计算步骤，并不计算任何值，为了得到计算结果，我们需要引入 **会话（Session）** 来负责图的计算。



下图很好地表示了TensorFlow的运行原理。

![](https://i.loli.net/2019/06/11/5cff57e53bb2b20404.gif)

该模型是一个简单的回归模型，数据从input开始，根据预先给定的权重（W）和偏差（b）一层一层地前向传播进行计算，第一层为ReLu layer，它具有矩阵乘法(tf.matmul)、偏向量加法(BiasAdd)和非线性激励(tf.nn.relu)操作；第二层为Logit layer；最后在SGD Trainer中计算梯度，并对权重和参数进行更新。



### 1.2 卷积神经网络基础

目前的卷积神经网络一般是由 **卷积层（Convolution Layer）+ 激活函数（Activation Function）**、**池化层（Pooling Layer）** 和 **全连接层（Fully Connected Layer）** 交叉堆叠而成的前馈神经网络，使用反向传播算法进行训练。



TensorFlow官方提供了高级API供用户调用，使用户无需使用代码来实现不同层的数学操作，最常见的API模块为`tf.nn`、`tf.layer`和`tf.contrib`。在使用中我们会发现这三个API模块之间存在大量的功能性重合，因此我们仅以最为常用的`tf.nn`模块为例进行介绍。



同时，需要注意的是，下文介绍的卷积、激活函数、池化、全连接只是构成计算层的几个**基本计算操作**，**一个计算层可能会由多个卷积、激活函数、池化组成**。



#### 1.2.1 卷积
##### 1.2.1.1 卷积介绍
在图像处理中，卷积通常作为特征提取的有效方法，目的在于提取并强化事物特征。一副图像在经过卷积操作后得到的结果我们称之为**特征映射（Feature Map）**。



在卷积过程中，我们需要确定 **卷积核（filter）** 和 **步长（Step）** 的大小，有时还需要根据自己的需求，决定是否需要进行**填充（padding）**。



每个filter有个数（Num）、长（Height）、宽（Width）、通道数（Channel）四个维度。长和宽也被成为卷积核的尺寸，通常我们使用3×3的卷积核。filter的深度与当前Feature Map的数量相同。因此，在模型中指定filter 时，只需指定个数、长和宽即可。

<img src="https://i.loli.net/2019/06/11/5cff9493c4ab548108.gif" style="zoom:50%">

上图表示的是一个filter为3×3×1，步长为1的二维卷积的过程，对5×5的Feature Map进行卷积后得到的Feature Map的大小为3×3。



可以推导得到卷积前后Feature Map的大小关系如下，其中N为输出Feature Map大小，W为输入Feature Map大小，F为filter大小，P为Padding数，S为步长：

<img src="https://i.loli.net/2019/06/11/5cff8754ee13e85778.png" style="zoom:50%">



##### 1.2.1.2 TensorFlow中的卷积

我们以最常用的二维卷积API `tf.nn.con2d`为例，其在TensorFlow官方文档中的介绍可参见此[链接](https://tensorflow.google.cn/api_docs/python/tf/nn/conv2d)。



在二维卷积API `tf.nn.con2d`中，需要指定输入、filter、步长、padding的方式（`same`或`valid`）等参数：
```python

tf.nn.conv2d(
    
    input,
    
    filter,
    
    strides,
    
    padding,                # 'same'或'valid'
    
    use_cudnn_on_gpu=True,
    
    data_format='NHWC',
    
    dilations=[1, 1, 1, 1],
    
    name=None)

```



使用实例如下，首先，我们需要定义一个卷积核的大小，通常我们不指定卷积核里的具体参数，用过随机生成的方法确定具体数值，而只指定卷积核的名称、长、宽、深、通道数。

```python

# 32个通道，大小为5×5×1的filter
w = tf.get_variable('weights', [5, 5, 1, 32])               

conv2 = tf.nn.conv2d( [$input] , w, [1, 1, 1, 1], 'SAME')   

```



#### 1.2.2 池化

##### 1.2.2.1 池化介绍

**池化（Pooling）** 是卷积神经网络中减少计算参数而又能保留重要信息的有效手段。



Pooling的本质是对数据进行抽样或聚合，通过选择该区域中的最大值或平均值来取代该区域中的所有值。这两种Pooling方法分别称为Max Pooling和Average Pooling。下图为Pooling的过程。

<img src="https://i.loli.net/2019/06/11/5cff94fa530da69044.gif" style="zoom:50%">

##### 1.2.2.2 TensorFlow中的池化
以Max Pooling为例，TensorFlow中的API为`tf.nn.max_pool`，其在TensorFlow官方文档中的介绍可参见此[链接](https://tensorflow.google.cn/api_docs/python/tf/nn/max_pool)。
```python

tf.nn.max_pool(
    
    value,
    
    ksize,                  # 每个输入tensor中每个维度上的窗口尺寸
    
    strides,                # 每个输入tensor中每个维度上的窗口滑动步长
    
    padding,                # 'same'或'valid'
    
    data_format='NHWC',
    
    name=None)
    
```
使用实例如下
```python

pool = tf.nn.max_pool(conv2, [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')

```



#### 1.2.3 激活函数

##### 1.2.3.1 激活函数介绍
使用一个单层感知机，我们可以学习得到一条能够将正负样本分分开直线，从而完成简单的二分类问题。多个感知机的叠加则能够画出更多的直线，进行更加复杂的分类。但是，感知机的叠加的本质是线性函数的叠加，得到的分类器仍然是一个线性方程，无法处理更为常见和普通的非线性问题。



因此，我们需要一个非线性函数来使这些线性分类器具有解决非线性问题的能力。这个非线性函数我们称之为**激活函数（Activation Function）**。我们将以最常见的激活函数**ReLu**为例，介绍其API具体的使用方法。




##### 1.2.3.2 TensorFlow中的激活函数
激活函数ReLu在TensorFlow中的API为`tf.nn.relu`，其在TensorFlow官方文档中的介绍可参见此[链接](https://tensorflow.google.cn/api_docs/python/tf/nn/relu)。
```python

tf.nn.relu(
    
    features,       #输入tensor
    
    name=None)

```
具体的使用示例如下：
```python

activation = tf.nn.relu(pool+b)

```



#### 1.2.4 全连接

##### 1.2.4.1 全连接介绍
上述的卷积、激活、池化的操作都是为了将原始数据映射到**特征空间**中，而全连接层所起到的作用就是将所学习到的特征表示通过线性变换映射到样本**标记空间**中。



但是由于全连接使用了卷积产生的所有局部特征，因此庞大的计算参数便能够占据整个网络80%左右的参数量。因此，一些性能优秀的网络如ResNet通常使用 **全局平均池化（Global Average Pooling）** 来替代全连接。



##### 1.2.4.2 TensorFlow中的全连接
TensorFlow中的API为`tf.layer.Dense`，其在TensorFlow官方文档中的介绍可参见此[链接](https://tensorflow.google.cn/api_docs/python/tf/layers/Dense)。
```python

tf.layers.dense(
    
    inputs,
    
    units,                          #输出的维度大小
    
    activation=None,
    
    use_bias=True,
    
    kernel_initializer=None,
    
    bias_initializer=tf.zeros_initializer(),
    
    kernel_regularizer=None,
    
    bias_regularizer=None,
    
    activity_regularizer=None,
    
    kernel_constraint=None,
    
    bias_constraint=None,
    
    trainable=True,
    
    name=None,
    
    reuse=None)

```
使用示例如下：
```

dense = tf.layers.dense(inputs=pool, units=1024, activation=tf.nn.relu)

```


### 1.3 实现一个计算层

在本实验中，我们提供了用于手写体数字识别的LeNet网络（见`Lab_01_visual.py`中的`def lenet`部分。



以第二个计算层为例，该计算层被命名为`conv2`，是一个由一个激活函数`Relu`，64个kernel大小为5×5×32的卷积核，以及一个`Max Pooling`函数构成的：

```python
    
with tf.variable_scope('conv2'):
        
	w2 = tf.get_variable('weights', [5, 5, 32, 64])
        
	b2 = tf.get_variable('biases', [64], initializer=tf.zeros_initializer())
        
	end_points['conv2'] = tf.nn.relu( tf.nn.conv2d(end_points['pool1'], 
                                          w2, [1, 1, 1, 1], 'SAME') + b2)
    
end_points['pool2'] = tf.nn.max_pool(end_points['conv2'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')
    
```
可以看到，它以第一层的输出`pool1`为输入进行卷积，输出为`pool2`。







## 2 CIFAR-10介绍
[CIFAR-01](http://www.cs.toronto.edu/~kriz/cifar.html)是计算机视觉领域中一个非常经典的数据集，它包含了10种不同类别物体，总共60000张32×32张彩色图像，分为50000张训练图片和10000张测试图片。



![](https://i.loli.net/2019/06/14/5d035d6e06bb364806.jpg)



在`cifar-10-data`文件夹中可以看到有5个`data_batch`和1个`test_batch`，每个batch包含一个python的字典结构。在该字典结构中，我们需要关注的关键字是`data`和`label`。



每一张图片是以被展开的形式存储（即一张32x32的3通道图片被展开成了3072长度的list），每一个数据的格式为uint8，前1024个数据表示红色通道，接下来的1024个数据表示绿色通道，最后的1024个通道表示蓝色通道。



### 2.1 数据转换
由于CIFAR-10数据集中的数据是以一个长度为3072的list进行储存的，因此我们首先需要将其转换为32×32×3的图像格式，方便我们为后续的模型测试提供可直接使用的图片。



由于TensorFlow官方所推荐的读写格式为`TFrecord`，其后缀为`.record`，因此我们还需要将图像格式转换为`.record`格式。Tensorflow官方为我们提供了丰富的API，我们可以通过直接调用这些API来实现`.record`格式的转换。



关于`TFrecord`格式的介绍以及对应API的使用方法可以点击[此链接](https://www.tensorflow.org/tutorials/load_data/tf_records)进行了解。



在`/lab_01/`下我们提供了一个名为`convert_tf_record_cifar.py`的python文件用于数据转换。



首先，我们先从二进制图像中读取对应的数据:
```python

# Read from binary file, and extract data and label respectively

fid = open(filename, 'rb')

py_dict = pickle.load(fid, encoding='iso-8859-1')

datas = np.asarray(py_dict['data'], dtype=np.uint8)

labels = np.asarray(py_dict['labels'])

```
将二进制数据转换为图像数据格式
```python

# convert data and label to default data format

img = np.zeros((32, 32, 3), dtype=np.uint8)

for ch in range(3):
 
	img[:, :, ch] = np.reshape(data[ch * 1024: (ch + 1) * 1024], (32, 32))

label = int(labels[i])

# cv2.imwrite('imgs/{}-{:05}.jpg'.format(label, i), img)

```
再将图像格式的数据转换为`TFrecord`格式，在这里我们按照tfrecord中标准的格式进行record文件内容写入。
```python

# data format declaration

example = tf.train.Example(
    
    features=tf.train.Features(
        
        feature={
            
            'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img.tostring()])),
            
            'label': tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))
        
        }
    
    )

)

# write to record file

writer.write(example.SerializeToString())

```



### 2.2 模型介绍

在此实验中，我们定义了一个`cifar_inference_slim`的模型，该模型能够实现对于`CIFAR`数据集的**分类**，它包含三个卷积层，两个全连接层和一个池化层。具体的模型定义代码在`/lab_01/cifar10.py`中的72~80行，该模型的定义代码如下：

```python

def cifar_inference_slim(X, is_training):
    
    with tf.variable_scope('cifar-10'):
        
        with slim.arg_scope([slim.batch_norm], is_training=is_training, center=True, scale=True, decay=0.9,epsilon=0.001):
            
            with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, padding="SAME"):
                
                with slim.arg_scope([slim.fully_connected], normalizer_fn=slim.batch_norm,
                                    
                                    weights_regularizer=slim.l2_regularizer(0.0005)):
                    
                    # 卷积层1
                    
                    net = slim.conv2d(X, kernel_size=[5, 5], num_outputs=32, stride=1, scope='conv1')
                    # 卷积层2
                    
                    net = slim.conv2d(net, kernel_size=[5, 5], num_outputs=32, stride=1, scope='conv2')
                    
                    # 池化层
                    
                    net = slim.max_pool2d(net, [3, 3], 2, padding="SAME", scope="conv2/pool")
                    # 卷积层3
                    
                    net = slim.conv2d(net, kernel_size=[3, 3], num_outputs=64, stride=2, scope='conv4')
                    
                    # 把多维的输入一维化，常用在从卷积层到全连接层的过渡
                    
                    net = slim.flatten(net, scope="conv2/flatten")
                    
                    # 全连接层1
                    
                    net = slim.fully_connected(net, 192, scope="fc2")
                    
                    # 全连接层2
                    
                    net = slim.fully_connected(net, 10, scope="pre_softmax")
                    
    return net

```
可以看到，此处的网络层的定义与本章1.3中有所不同，这是因为我们使用了TensorFlow的`slim`模块。



`slim`库中提供了`data`、`evaluation`、`layer`、`learning`、`losses`、`regularizers`、`variable`等API以供调用，感兴趣的用户可点击[**此链接**](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)进行阅读。



在此我们仅针对比较常用的几个API进行介绍。



#### 2.2.1 `slim`库介绍
`slim`库可以消除原生tensorflow里面很多重复的模板性的代码，让代码更紧凑，更具备可读性。



我们首先回顾一下不使用`slim`来构造一个计算层的方法:
```python

with tf.variable_scope('conv2'):
    
    w2 = tf.get_variable('weights', [5, 5, 32, 64])
    
    b2 = tf.get_variable('biases', [64], initializer=tf.zeros_initializer())
        
        end_points['conv2'] = tf.nn.relu( tf.nn.conv2d(end_points['pool1'], 
                                          w2, [1, 1, 1, 1], 'SAME') + b2)
    
    end_points['pool2'] = tf.nn.max_pool(end_points['conv2'], [1, 2, 2, 1], [1, 2, 2, 1], 'SAME')
    
```
可以明显地看到，通过`slim`，我们只需要一条代码便能定义一个计算层。`slim`中会自动根据输入`feature map`的尺寸，计算对应的`kernel`维度，而不需要用户自己进行计算。



在使用`slim`库前，需要通过以下代码进行`slim`库的导入：
```python

import tensorflow as tf

import tensorflow.contrib.slim as slim

```



#### 2.2.2 常见的`slim` API

##### 2.2.2.1 使用`slim.con2d`实现一个**卷积层**

`slim.conv2d`的源函数定义为：

```python

def convolution(inputs, num_outputs, kernel_size, stride=1, padding='SAME',
                
                data_format=None,
                
                rate=1,
                
                activation_fn=nn.relu,
                
                normalizer_fn=None,
                
                normalizer_params=None,
                
                weights_initializer=initializers.xavier_initializer(),
                
                weights_regularizer=None,
                
                biases_initializer=init_ops.zeros_initializer(),
                
                biases_regularizer=None,
                
                reuse=None,
                
                variables_collections=None,
                
                outputs_collections=None,
                
                trainable=True,
                
                scope=None)

```
具体使用例子：
```python

input = ...

net = slim.conv2d(input,256,[3,3],strides=1,scope=`conv1`)

#由于我们没有指定其他参数，如stride和激活函数，因此会默认strides=1，activation=nn.relu

```
##### 2.2.2.2 使用`slim.max_pool2d`实现一个**池化层**
`slim.max_pool2d`的源函数定义为：

```python

def max_pool2d(inputs, kernel_size, stride=2, padding='VALID',
               
               data_format=DATA_FORMAT_NHWC,
               
               outputs_collections=None,
               
               scope=None)

```
具体使用例子：
```python

input...

net = slim.max_pool2d(input, [3, 3], 2, padding="SAME", scope="conv1/pool")

```
同样地，`slim`也提供了`slim.avg_pool2d` API，用户可以自行前往官方文档查询其源代码。

##### 2.2.2.3 使用`slim.fully_connected`实现一个**全连接层**
`slim.fully_connected`的源函数定义为：

```python

def fully_connected(inputs, num_outputs, activation_fn=nn.relu,
                    
                    normalizer_fn=None,
                    
                    normalizer_params=None,
                    
                    weights_initializer=initializers.xavier_initializer(),
                    
                    weights_regularizer=None,
                    
                    biases_initializer=init_ops.zeros_initializer(),
                    
                    biases_regularizer=None,
                    
                    reuse=None,
                    
                    variables_collections=None,
                    
                    outputs_collections=None,
                    
                    trainable=True,
                    
                    scope=None)
    
```
具体使用例子：
```python

net = slim.fully_connected(net, 10, scope="pre_softmax")

```
##### 2.2.2.4 `slim.arg_scope`的使用方法
如果网络中存在大量相同的参数，比如所有的卷积层都使用了3×3的卷积，卷积步长都为2，激活函数都为Relu。尽管我们可以使用`slim.conv2d`进行反复构造，但这就会使得代码看起来不够整洁。因此，我们可以使用`slim.arg_scope`来指定特定`scope`中算子的参数。



`slim.arg_scope`的源函数定义为

```python

arg_scope(list_ops_or_scope, **kwargs)

```
其中，`list_ops_or_scope`表示操作列表或作用域列表，`kwargs`为以`keyword=value`方式显示的参数。以上文模型定义中的其中一个`slim.arg_scope`为例：
```python

with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm, padding="SAME"):
    
```
我们指定所有使用了`slim.conv2d`的卷积层，都使用`slim.batch_norm`作为标准化方法，填充方式都为`SAME`。在指定了这些参数之后，模型中所有使用了`slim.conv2d`的卷积层都将以指定的参数为默认值，用户不必再声明这些参数。



### 2.3 数据预处理与网络模型训练
在完成了模型的搭建之后，我们便顺理成章地需要对模型进行训练。而在模型训练之前，我们需要了解一个非常重要的概念————**数据预处理**。



#### 2.3.1 数据预处理
数据预处理的主要目的有两点：一是用于增强图像的特征，比如对图像进行高通滤波（突出边缘）、低通滤波（平滑图像）等从而改进特征提取、图像分割、匹配和识别的准确性；二是增加数据量，比如对图像进行求反、旋转、压缩、对比度调整、灰度转换等操作，从而提高模型的鲁棒性。
<img src="https://i.loli.net/2019/06/18/5d088eabc711529114.jpg" style="zoom:75%" align=center>



在本实验中，我们使用的图像预处理方法为随机裁剪、左右翻转、亮度和对比度调整：

```pyhton

distorted_image = tf.random_crop(image_float, [24, 24, 3])

distorted_image = tf.image.random_flip_left_right(distorted_image)

distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)

distorted_image = tf.image.random_contrast(distorted_image, lower=0.2, upper=1.8)

float_image = tf.image.per_image_standardization(distorted_image)

```
TensorFlow中的`tf.image`还提供了其他可用于图像处理的API，感兴趣的用户可通过点击**此链接**进行阅读学习。


#### 2.3.2 网络模型训练
本实验中训练部分的核心代码如下：
```python

train_loss = _loss(feature, Y)

global_step = tf.train.get_or_create_global_step()

lr = tf.train.exponential_decay(0.01, global_step, num_of_samples_per_decay, 0.5, staircase=False)

 # batch_norm update

update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)

with tf.control_dependencies(update_ops):
    
    optimizer = tf.train.MomentumOptimizer(lr, 0.9).minimize(train_loss, global_step=global_step)
    
```
- `_loss`函数用于求解预测值与groundtruth之间的距离。
- `global_step`用于记录执行的步数，每更新一次网络参数，global_step会自动加一。
- `tf.train.exponential_decay`用于使用指数衰减的方法来逐渐减小学习速率。TensorFlow官方给出了其详细的API介绍 。
    ```python
    
    tf.train.exponential_decay(
    
    learning_rate,
    
    global_step,
    
    decay_steps,
    
    decay_rate,
    
    staircase=False,
    
    name=None)
    
    ```
- `update_ops`用于更新网络的参数。
- `optimizer`中我们使用了**动量优化**，不同于常见的**随机梯度下降SGD**，**动量优化**算法借用了物理中的动量概念，它模拟的是物体运动时的惯性，即更新的时候在一定程度上保留之前更新的方向，同时利用当前batch的梯度微调最终的更新方向。这样一来，可以在一定程度上增加稳定性，从而学习地更快，并且还有一定摆脱局部最优的能力。其在TensorFlow的API介绍可以参考[此链接](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer)：https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer
  >**Note：**
  关于不同优化方法的对比，请参见此链接：https://blog.csdn.net/u010089444/article/details/76725843







## 3. 练习

### 3.1 模型训练与验证
在`lab_01`文件夹中存在三个文件：
- `cifar-10-data`：CIFAR10数据集，有5个用于训练的`data_batch`和一个用于测试的`test_batch`

- `convert_tf_record_cifar.py`：数据转换程序，用于将CIFAR10二进制图像数据转化为TensorFlow标准的record格式

- `cifar.py`：本次实验需要使用的程序



#### 3.1.1 数据转换

启动docker，通过`cd`命令`cifar_train`文件夹，之后，在此路径下输入如下命令。
```shell

python convert_tf_record_cifar.py

```


该脚本会从`./cifar-10-data/`读取对应的二进制数据文件，并转化tfrecord文件。脚本执行结束后，会生成`cifar10_train.record`和`cifar10_test.record`两个tfrecord文件。



如果用户想要看到转换成图像格式的训练数据，可以把`convert_tf_record_cifar.py`中第40行`cv2.imwrite`的注释打开。



#### 3.1.2 模型训练
用户可使用`python cifar10.py -h`查看脚本使用说明，脚本中几个比较重要的参数如下

- `num_decay`代表每经过多少步迭代将学习率减半
- `model_type`代表模型的选择，这里我们提供了两种预定义的模型结构`slim`和`large`，其中`large`模型需要用户在下一个实验中自行定义
- `mode`表示使用训练模式`train`还是测试模式`test`



具体命令如下：

```shell

python cifar10.py --mode train --gpu 0 --model slim --save_path ./model_slim/

```
训练完成后，用户可调用`tensorboard --logdir ${save_path}`调用图形化界面查看训练任务相关信息。这里我们在模型图中插入了summary节点，用来记录想要追踪的重要参量。



图形化界面的开启具体命令如下：

```shell

tensorboard --logdir ./model_slim/

```

输入该指令后，终端中会出现一个tensorboard的链接，右键打开链接即可。打开链接后的界面如图：

![tensorboard2.png](https://i.loli.net/2019/03/12/5c8788048ff4a.png)



更多关于tensorboard的内容，请参考tensorflow[官网](https://www.tensorflow.org/guide/summaries_and_tensorboard?hl=zh-cn)。



#### 3.1.3 模型验证

使用如下命令完成模型测试：
```python

python cifar10.py --mode test --gpu 0 --model slim --save_path ./model_slim/

```

该脚本从${save_path}中读取对应的模型文件，并在测试集上逐张进行测试，并显示对应结果。



结果显示如下：

```shell

[INFO]: Starting testing ...

[INFO]: Load Model from model_large/model-ckpt-10000

INFO:tensorflow:Restoring parameters from model_large/model-ckpt-10000

[INFO]: Restoring parameters from model_large/model-ckpt-10000

[INFO]: IMG 1/10000 --> [CORRECT] Prediction: [4]; Gt-label: [4]

[INFO]: IMG 2/10000 --> [CORRECT] Prediction: [6]; Gt-label: [6]

[INFO]: IMG 3/10000 --> [WRONG] Prediction: [0]; Gt-label: [3]

[INFO]: IMG 4/10000 --> [CORRECT] Prediction: [1]; Gt-label: [1]

[INFO]: IMG 5/10000 --> [CORRECT] Prediction: [8]; Gt-label: [8]

```

测试时我们提取每张图像最后一层全连接的输出，其维度为10，与CIFAR-10数据集类别数相同。我们提取10个数字中最大的对应的类别标签作为该图像的类别预测结果，如果与groundtruth类别相同，则为正确，反之则为错误。



### 3.2 搭建一个神经网络并进行训练

在`cifar10.py`的第94行处搭建一个网络模型，要求如下：



- 搭建一个具有以下结构的网络模型，其中输入已经提前给定为X，用户直接使用即可

<img src="https://i.loli.net/2019/07/17/5d2e927d907d517667.png" style="zoom:90%">

- 使用`slim`库进行模型搭建
  - 批标准化`batch normalization`的参数与示例模型保持一致

  - 所有卷积层使用批标准化`batch normalization`，填充方式为`SAME`

  - 所有全连接层使用批标准化`batch normalization`，权重正则化方式使用`l2正则化`



在完成了网络模型的搭建之后，通过3.1实验相同的步骤进行模型的训练，并进行训练结果的验证，最后比较观察随着模型深度的加深，检测效果是否变化。



需要注意，在`cifar10.py`程序中，用户自定义的模型为`large`。在训练和验证中，只需将`model`的参数从`slim`改为`large`。

```shell

python cifar10.py --mode train --gpu 0 --model large --save_path ./model_large/

python cifar10.py --mode test --gpu 0 --model large --save_path ./model_large/

```
