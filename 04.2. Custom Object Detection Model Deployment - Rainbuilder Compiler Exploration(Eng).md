# Custom Object Detection Model Deployment - Rainbuilder Compiler Exploration



This tutorial is intended to introduce the use of the `Compiler` in the RainBuilder Compilation Tools and the deployment process of the model on the FPGA Accelerator Card.

>  Note: This experiment needs to be done in **server** with docker



The tutorial is organized as follow,




- [1. Introduction and Description of Rainbuilder Compiler](#1-Introduction-and-Description-of-Rainbuilder-Compiler)
- [2. Usage steps of RbCli](#2-Usage-steps-of-RbCli)
  - [2.1 Freeze Model - `RbCli freeze`](#21-Freeze-Model---RbCli-freeze)
  - [2.2 Generate SG - `RbCli sg`](#22-Generate-SG---RbCli-sg)
  - [2.3 Quantification - `RbCli quant`](#23-Quantification---RbCli-quant)
  - [2.4 Optimize Commands- `RbCli opt`](#24-Optimize-Commands--RbCli-opt)
- [3. Model Deployment on FPGA](#3-Model-Deployment-on-FPGA)
  - [3.1 Preparation of Model Deployment File](#31-Preparation-of-Model-Deployment-File)
  - [3.2 Run the Model](#32-Run-the-Model)
- [4.Exercise](#4Exercise)







Goal:
1. How to use`RainBuilder` to deploy the model to the Nebula FPGA Accelerator.
2. Use of the compiler command line tool `RbCli` and `compiler` workflow







## 1. Introduction and Description of Rainbuilder Compiler
According to the `Compiler` introduced in *Custom Object Detection Model Deployment - Intro* , `Compiler` supports parsing and transformation of the network models by command-line tool `RbCli`.

![SG flow.jpg](https://i.loli.net/2019/07/23/5d36ece8729fc16286.png)



`RbCli` consists of four parts: `RbCli freeze`、`RbCli sg`、`RbCli quant`、`RbCli opt`，described as follows：

```bash

$ RbCli
Usage: RbCli [OPTIONS] COMMAND [ARGS]...

 RbCompiler CLI: a command-line tool for the RainBuilder Compiler.

Options:
--debug / --no-debug
-v, --version
--help                Show this message and exit.

Commands:
export  Export model coefficient from SG IR
freeze  Freeze a TensorFlow model from checkpoints
opt     Optimization SG from given SG IR
quant   Quant SG from given SG IR
sg      Generate SG IR from given frozen model

```







## 2. Usage steps of RbCli

In `Neural Network Design with TensorFlow`, we get a trained model `inference_model`under the path `/lab_02` . The file structure in  `inference_model` is as follows：

```bash

--inference_model
    |--ckpt.meta
    |--ckpt.data-00000-of-00001
    |--ckpt.index
    |--checkpoint
    
```



Next, we will use the this file as a basis to explain how to deploy a Tensorflow model on the Nebula FPGA accelerator based on `compiler` step by step.



### 2.1 Freeze Model -  `RbCli freeze`
#### 2.1.1 Usage
`RbCli freeze`is used in the following way, where `[Model_dir]`is the path of the model  files we got during or after training. 

```bash

RbCli freeze [Model_dir]

```



The files in `inference_model` are the input of `RbCli freeze`. The output is the frozen model file `*.pb`  which defines the structure of the inference graph and the parameters of each layer in the neural network. 



#### 2.1.2 Command Description

The freeze command `RbCli freeze` converts the result of the model checkpoint  file to the frozen model `*.pd`. A trained neural network model should contain the following three files under the `checkpoint` folder path：

1. `*.meta`: Meta information for the model.
2. `*.data*`: Model training data files.
3. `*.index`: Files of Index.

>**Note：**
TensorFlow preserves the results during model training aotumatically. Before freezing the model, you need to select the one of the training results in the checkpoint file, usually the latest one. You must cannot freeze all the training results.



#### 2.1.3 Introduction of Command Parameters

The specific description of `RbCli freeze` is as followed：
```bash
    
    $ RbCli freeze --help
    
	Usage: RbCli freeze [OPTIONS] MODEL_DIR

  	  Freeze a TensorFlow model from checkpoints

	Options:
  	-m, --model-file PATH         Freeze model file path with .pb suffix. If it
                                  is not specified, default generated in the
                                  current directory, name model.pb
  	-o, --output-node-names TEXT  Output node names, comma separated. If it is
                                  not specified, the default by RbCompiler to
                                  find and then you choose.
  	--logdir PATH                 Save the log directory for viewing tensorboard
  	--help                        Show this message and exit.
    
```

- ``MODEL_DIR``：Required parameters, representing the storage path of the model file.

- ``--model-file``: Optional parameter that specifies the output `.pb` filename. If you do not specify , a file named ``model.pb`` will be generated under the current path.
- ``--output-node-names``: Optional parameter that  specifies the nodes for freezing. If you need multiple output nodes, you should enter the name of output nodes and seperate them with commas. If the parameter is not specified, `RbCli` will automatically analyze the model and find the possilble nodes and select them.



Since `RbCli` can automatically search for the output node, it's not necessary to specify the node name or sequence number when running `RbCli freeze`. The specified node output function is used only when a specific output node is not found, or when a node name is incorrect.



### 2.2 Generate SG - `RbCli [frontend]`

Note that the frontend of RbCompiler can analysis DL framework like TensorFlow, Caffe, ONNX, to covert the model from these framework, we should use corresponding instruction.

```bash

# TensorFlow 
RbCli [OPTIONS] tf [ARGS]... 

# Caffe 
RbCli [OPTIONS] caffe [ARGS]... 

# ONNX 
RbCli [OPTIONS] onnx [ARGS]...

```



#### 2.2.1 Usage
The way to generate SG with `RbCli` is as follows：
```bash

RbCli [front-end-op] [Model_file]

```


The command uses the above  frozen model `*.pb` file as input，generates a file ended up with `*_sg.pbtxt`，an intermediate representation we call Streaming Graph, **SG IR**. 



#### 2.2.2 Description of Command

The command takes the above  frozen model `*.pb` file as input，generating **SG IR** file. **SG IR** is a serial representation of a flow diagram. A flow diagram is consist of two parts：

1. Model structure file: use `protobuf` protocol , saved in a file suffixed with `pbtxt'.`
2. Model parameter file: saved in `h5py` format in the file suffixed with `h5'.`



#### 2.2.3 Introduction of Command Parameters

The command is described as follows:

```bash
    
    $ RbCli tf --help

	Usage: RbCli tf [OPTIONS] MODEL_FILE

      Generate SG IR from given tf frozen model

	Options:
 	-n, --model-name TEXT           Model name.
  	-o, --output-dir PATH           Output directory, save generated SG IR.
  	-s, --input-image-shape TEXT    A default shape of the input image for the
                                    model.
  	-f, --data-format TEXT          One of channels_last or channels_first,
                                    default channels_last, like 'NHWC' is
                                    0,2,3,1.
  	-c, --custom-layer-config PATH
  	--with-json BOOLEAN             Whether to export the json file of SG IR,
                                    default False
  	--with-coeff BOOLEAN            Whether to export model coefficients such as
                                    weights and bais, default False
  	--help                          Show this message and exit.

```
- `-n` is used to modify the name of the `*.pb` file.
- `-o` is used to specify the path to store the model description file. If you do not specified, RbCli will save the output file in the current directory.
- `-s` is used to specify the shape of input image, such as 1,256,256,3. If the input model shape is dynamically transformed, use this parameter to set a specific shape.
- `-f` selects the arrangement of the shape of the data, you can enter  a sort of number like `0,1,2,3`, 1 for batch size, 2 for channel, 3 for height, and 4 for width.
- `-c` is used to specify the path of the custom layer profile (json) in the user model.
- `-v` is used to set the version number for`*.pbtxt`. You can enter `V1` or `V2`，the default is `V2`.
* ``--with-json``: Export json file, the default is `false`.
* ``--with-coeff``:  Set the parameters of whether to export the model, such as `weights`and `bias`.




### 2.3 Quantization - `RbCli quant`
#### 2.3.1 Usage
The command `RbCli quant` is used as follows：
```bash

RbCli quant [*.pbtxt] [*.h5] [preprocess_script] \

            --preprocess-range -123, 151 \
            
            --img-dir [Database_path] \
            
            --output-dir [Frozen_Model_path] \
            
            --with-coeff True
            
            --gpu-config [gpu_config file]
            
```



`*_sg.pbtxt` and `*_sg.h5` are the input of this command, here we provide a preprocess script  `preprocess_ssd.py` to preprocess the images in database `fddb` for model quantization, the path to this script and database is `/lab_04.1/`.



#### 2.3.2 Description of Command 

We can use `RbCli quant` to perform an 8-bit quantization on the **SG IR**. Before performing the quantization, users need to prepare a certain amount of data beforehand, the data should be as similar as possible to the actual data in the real scenarios, and use python as the data processing method.



#### 2.3.3 Introduction of Command Parameters

The detailed description of the command `RbCli quant` is as follows：


```bash
$ RbCli quant --help

Usage: RbCli quant [OPTIONS] SG_DEF_FILE SG_H5_FILE PREPROCESS_PY

  Quant SG from given SG IR

Options:
  --use-kld BOOLEAN         Whether to use KLD quantization, default False.
  --float-coeff PATH        Folder path for model coefficients.
  --img-dir PATH            Input data set directory path used for SG
                            quantization, default current directory.
  --preprocess-range TEXT   Theoretical input range of the model after pre-
                            processing. the format is 'min,max', defalut is
                            0,255
  --output-dir PATH         Output directory, save Quant SG IR.
  --with-sim BOOLEAN        Save the SG IR used by the raintime sim model,
                            default False
  --with-sim-align BOOLEAN  Save the SG IR used by the raintime sim model and
                            open model channel 64 alignment, default False
  --with-fakequant BOOLEAN  Save quantified results, default False
  --with-coeff BOOLEAN      Whether to export model quant coefficients,
                            default False
  --gpu-config PATH         GPU configuration file.
  --help                    Show this message and exit.

```

- ``--preprocess-range``: The theoretical input range of the model after pre-processing the input image. This parameter specifies the minimum and maximum `min, max`, and the default input range is [0,255].
- ``--img-dir``: The input data path that is required for the **SG IR** quantization operation.
- ``--output-dir``: The output path of the quantized result.
- ``--with-coeff``: Whether to export the model, such as  `weights` and `bias`.
- ``--gpu-config``: The GPU configuration file, enables the quantization operation to run on the GPU. Configuration files are provided by RainBuilder Compiler.
- ``--with-sim``: The debugging parameters, do not need to be specified in actual use.
- ``--with-fakequant``: The debugging parameters, do not need to be specified in actual use.




### 2.4 Optimize Commands- `RbCli opt`
#### 2.4.1 Usage
`The RbCli opt` command is used as follows. 

```bash

RbCli opt [*_sg.pbtxt] [*_sg.h5] [opt_config] -o [output_path] -c true

```



The `opt_config` is the description file of FPGA cards, which is used to allocate the computing execution devices for different nodes in the model. Here, the `opt_config` file is `CAISA.pbtxt` we offer in `/lab_04.1/`.



#### 2.4.2 Description of Command 

If you want to deploy the neural network models on the Nebula FPGA accelerator, you need to generate a model file that matches the hardware computing resources. This step first integrates multiple SGNode operators into one operation according to the computing resources of the hardware, which saves IO time consumption. In addition, because the computing resources and architecture of each board are different, not all SGNodes can be deployed on  FPGA hardware. There are some special operations that need to be assigned to run on CPU; Note that, this step also evaluates the optimal computing resources and parallelism parameters based on the hardware resource configuration.



The command `RbCli opt` implements two optimizations for FPGA hardware：

| Optimization Strategy | Function                  |
|       --   |                         --            |
| Device     | Assign execution device (FPGA or CPU) for SG nodes |
| Fusion     | Integrating multiple operators into one to improve resource and computational efficiency |



#### 2.4.3 Command Parameter Introduction

The detailed description of the command`RbCli opt is as followed:


```bash

$ RbCli opt --help

Usage: RbCli opt [OPTIONS] SG_DEF_FILE SG_H5_FILE OPT_CONFIG

  Optimization SG from given SG IR

Options:
  -c, --ch-align BOOLEAN  if True, open model channel 64 alignment.
  -o, --output-dir PATH   Output directory, save Opt SG IR. If not specified,
                          the default is to the directory where the
                          sg_def_file file is located.
  --help                  Show this message and exit.
  
```

- `SG_DEF_FILE`: Quantified model structure.
- `SG_H5_FILE`: Model parameters in `.h5`.
- `OPT_CONFIG`: Card hardware parameter definition file.
- `-o`：Specify the output path



At this point, the model description file `*_opt_sg.pbtxt` and the model's parameter file `*_quant_coeff/coeff_little` are generated. By deploying these two files on the FPGA, the acceleration of the model can be realized.








## 3. Model Deployment on FPGA
### 3.1 Preparation of Model Deployment File 

The SSD model needs three model related files to be deployed on the Nebula FPGA accelerator：
- `post_param`，Post-processing file, which is generated in the "Target Detection Model Training Course"，The storage path is`./lab_02`

- `*_opt_sg.pbtxt`，quantified and optimized model structure file，The storage path is `./lab_04/lab_04.1/`

- `coeff_little`，quantified and optimized model structure file，the storage path is ``./lab_04/lab_04.1/`, the same as the structure file.


For convenience, it is better to place these files in a single directory like  `./lab_04/lab_04.1/object_detection/ssd`, The file structure of the file is：


```bash

--ssd
    |--ssd_opt_sg.pbtxt
    |--ssd_config.txt
    |--post_param
    |--ssd_quant_coeff
    |   |--coeff_little
    
```




### 3.2 Run the Model

enter the `ssd` folder and run the model by executing the following command.


```bash

./image_object_detection \						#Executable file we offerd

  --sg ./ssd_opt_sg.pbtxt \						#Model structure file
  
  --images ../fddb/testing-data/ \				#Test image
  
  --data ./ssd_quant_coeff/coeff_little/ \		#Model coefficient file
  
  --processor ssd \
  
  --batch 1 \
  
  --group 1000 \
  
  --num_threads 2 \
  
  --image_list ../references/fddblist.txt \
  
  --output_file ../predictions.txt \
  
  --from_file=true \
  
  --config_file ../ssd_config.txt \				#Postprocessing config file we offerd
  
  --param_path ./poat_param/ \					#post process parameter
  
  --with_image_output=false
  
```



> **Note:**
>
> We can see that we entered the corresponding parameters and call the executable application called  `image_object_detection` to execute the model. `image_object_detection` is our pre-compiled runner program, which is based on `RbRuntime`. We will detail the specific development method in "Custom Object Detection Model Deployment - RainBuilder Runtime Exploration".



## 4.Exercise

In the experiment "Neural Network Design with TensorFlow", we obtained the checkpoint file of the target detection model.



This experiment requires:

1. Compile the model with `Compiler`. When the compilation is completed, you should get the model description file `*_opt_sg.pbtxt` and the model parameter file `coeff_little`.
2. Deploy the compiled model file to the FPGA and execute the model.

