 # Custom Object Detection Model Deployment - Rainbuilder Runtime Exploration



本实验对`RbRuntime`以及模型数据的前后处理进行了较为详尽的介绍。在本教程中，我们介绍了`RbRuntime`中常用API，以及如何使用这些API搭建一个适用于CAISA架构的模型运行程序。同时，我们在教程中也介绍了典型推演任务中图像的前处理方法和模型输出数据的后处理方法。



本次教程安排如下



- [1. `RbRuntime`简介](#1-rbruntime简介)
- [2. Runner程序创建](#2-runner程序创建)
    - [2.1 创建SG对象](#21-创建sg对象)
    - [2.2 加载模型参数](#22-加载模型参数)
    - [2.3 创建Runner](#23-创建runner)
    - [2.4 运行Runner](#24-运行runner)
- [3. 了解预处理与后处理](#3-了解预处理与后处理)
    - [3.1 图像预处理](#31-图像预处理)
    - [3.2 模型后处理](#32-模型后处理)
        - [3.2.1 模型输出数据处理](#321-模型输出数据处理)
        - [3.2.2 NMS介绍](#322-nms介绍)
- [4. `Runner`编译方法](#4-runner编译方法)
- [5.练习](#5练习)
    - [5.1 图像预处理的实现](#51-图像预处理的实现)
    - [5.2 数据后处理](#52-数据后处理)
    - [5.3 模型部署](#53-模型部署)







预期目标：

1. 了解如何使用RbRuntime提供的API进行Runner程序的构建
2. 掌握面向推演任务的典型图像预处理的实现
3. 掌握基于SSD架构目标检测算法模型输出数据的后处理实现方法







## 1. `RbRuntime`简介

RainBuilder Runtime，即`RbRuntime`，是一个在FPGA系统上进行卷积神经网络计算处理的库，RbRuntime用于运行由`RbCompiler`生成的SG，根据SG描述部署计算过程并执行计算，通过权值文件初始化计算节点所依赖的数据。



`RbRuntime`可以根据SG描述所提供的每个节点的信息，分配不同的计算函数、数据类型、计算设备给不同的节点。



`RbRuntime`也提供了简洁的调用接口，仅需几行代码即可整合`RbRuntime`的计算功能到目标应用中。



`RbRuntime`的使用流程可以大概分为以下几步。

>1. 加载pbtxt到SGDef对象，使用SGBuilder将从SGDef创建出SG
>2. 加载模型参数数据到SGDataMap
>3. 创建SGRunner
>4. 准备输入数据的SGDataMap，并调用SGRunner的Run或者RunAsync开始计算，最后得到计算结果的输出SGDataMap

![](https://i.loli.net/2019/07/05/5d1ebc7dc124b27139.png)







## 2. Runner程序创建

在上一个实验《Rainbuilder Compiler Exploration》中，我们已经使用`compiler`完成了基于SSD框架的目标检测模型数据的解析和导出，并得到了如下模型文件结构：

```shell
/object_etection
  |-image_object_etection
  |-run.sh
  /images_ssd
    |-img_55.jpg
    |-...
  /ssd
    |-ssd_config.txt
    |-ssd_opt_sg.pbtxt
    /post_param
      |-post_anchor_0.bin
      |-...
    /quant
      /float_little
      |-config.json
      |-...
```
在此实验中，我们以`/lab_04.2/object-detection/image_object_detection.cc`为例进行讲解。



在`image_object_detection.cc`中，我们使用`ImageObjectDetection`类用来管理运行模型过程中用到的数据和流程。



以下是`image_object_detection.cc`的main函数：
```c++

ImageObjectDetection img_detect{FLAGS_sg, FLAGS_data, FLAGS_num_threads,
                                FLAGS_batch, (float)FLAGS_threshold};

ImageProcessorFactory factory;

//读取SSD配置参数
factory.SetConfigFile(FLAGS_config_file);

//指定使用SSD后处理程序
factory.SetFlag(FLAGS_processor);

//读取SSD anchor相关信息
factory.SetParamPath(FLAGS_param_path);

img_detect.BatchRun(FLAGS_images, factory);

```


`ImageObjectDetection`类的定义如下：

```c++

  ImageObjectDetection(std::string const &sg_def_file,
                       std::string const &data_dir, int num_threads,
                       int input_batch, float threshold) {
      
    this->sg_def_ = LoadSGDefFromFile(sg_def_file.c_str());
    
    this->sg_ = BuildSG(this->sg_def_);
      
    this->const_data_ = LoadSGDataMapFromDir(data_dir.c_str());
      
    this->input_node_def_ = FindImageInput(this->sg_def_);
      
    this->runner_ =
        BuildSGRunner(this->sg_, this->const_data_, num_threads, input_batch);
      
    this->threshold = threshold;
  }

```



### 2.1 创建SG对象

RbRuntime提供了如下几个API，用于在初始化时将pbtxt加载到SGDef数据结构中，并将SGDef数据转换为SG对象。
```c++

this->sg_def = LoadSGDefFromFile("/object_etection/ssd/ssd_opt_sg.pbtxt");

this->sg = BuildSG(this->sg_def);

```


在我们提供的`image_object_detection.cc`中，对应的使用方法如下：

```c++

this->sg_def_ = LoadSGDefFromFile(sg_def_file.c_str());

//加载模型结构定义文件，输入参数为模型结构文件pbtxt所在路径
this->sg_ = BuildSG(this->sg_def);

```



### 2.2 加载模型参数

使用`RbRuntime`提供的API加载模型参数并确定输入节点信息：
```c++

this->const_data = LoadSGDataMapFromDir("/object_etection/ssd/quant/float_little");

this->input_node_def = FindImageInput(this->sg_def);

```


在我们提供的`image_object_detection.cc`中，对应的使用方法如下：

```c++
//加载模型参数文件，输入参数为模型参数文件所在路径
this->const_data_ = LoadSGDataMapFromDir(data_dir.c_str());

//确定输入节点
this->input_node_def_ = FindImageInput(this->sg_def);

```



### 2.3 创建Runner

创建SGRunner，指定工作线程数为num_threads，并在`img_detect.BatchRun()`中执行预处理和后处理，前后处理的细节将在后续内容中详述。
```c++

this->runner_ = BuildSGRunner(this->sg_, this->const_data_, num_threads, input_batch);

```






### 2.4 运行Runner

最后启动Runner开始计算:
```

auto output_data_map = runner->Run(sg, const_data, input_data_map);

```


在我们提供的`image_object_detection.cc`中，对应的使用方法如下：

```

runner->RunAsync(sg_, const_data_, pair.second);

```








## 3. 了解预处理与后处理

由于算法模型可以接受的数据格式和类型是固定的，在执行模型之前，需要预先将数据处理成可被网络识别的格式和类型。在运行一个图像分类或目标检测算法前，我们需要确保输入图像的大小符合SG(*.pbtxt)的要求，因此我们需要对图像进行预处理。



当SG在RbRuntime中结束运行后，我们会得到一个或几个输出张量(tensor)，为了使结果更加直观，对于分类算法，是返回分类标签，对于目标检测算法，则通常需要在图片中将目标物用矩形框框选出来。因此在后处理中，程序代码对输出张量进行计算，确定矩形框的位置和大小并且在目标物上画框，或对输出张量进行标签映射。



### 3.1 图像预处理

本次实验中，我们提供的SSD模型的输入大小为256×256的RGB图片，因此，我们在对于输入图像的前处理应包含如下几个步骤：
1. 读取图像

2. 调整通道顺序由BGR调整为RGB

3. 将图像缩放到256x256

4. 对图像减平均，R通道-123.0，G通道-117.0， B通道-104.0

   > (1)为什么要调整图片通道顺序？
   >
   > 由于cv::Mat加载得到的图像为BGR格式，在训练时，我们使用的是RGB格式的图片，为了使推演结果正确，我们需要在图像预处理时对图像通道进行调整。
   >
   >
   >
   > (2)为什么要减平均？
   >
   > 在训练时，如果输入数据不是0中心分布的而是全为正的话，在使用ReLU函数作为激活函数时，各层的激活值也是正的，那么反向传播时对某层权重w的梯度也会是全为正的或负的，这会导致梯度下降时目标函数的寻优路线呈现不期望的Z字型，不利于梯度下降算法的有效收敛。因此在训练时我们往往构造以0位中心分布的数据，在进行推演时，也应构造同样类型的数据。-123.0，-117.0，-104.0是VGG-16官方所使用的对应RGB三个通道的均值。



本次实验的图像预处理在`image_object_detection.cc`中的`PreProcess()`里函数实现。



### 3.2 模型后处理

#### 3.2.1 模型输出数据处理

在进行ssd网络定义时，会定义一些anchor(标准框)，ssd网络不会直接推断出物体在图片中的坐标，而是推断出坐标与这些anchor的的相对偏移。若目标推断框的中心坐标和高宽为(x, y, h, w), 一个anchor的坐标和高宽为(xa, ya, ha, wa), 那么ssd网络输出的是(x’, y’, h’, w’), 它们间的关系如下式所示。

> x’ = (x - xa) / wa；
>
> y’ = (y - ya) / ha;
>
> w’ = log(w / wa)；
>
> h’ = log(h / ha);



后处理以ssd网络的输出(x’, y’, h’, w’)为输入，结合anchor(xa, ya, ha, wa)，**逆用上式**，便可以计算推断框的中心坐标和高宽(x, y, h, w)。



在上一个实验中，我们搭建了使用六个不同尺度特征图进行目标检测的SSD网络（如下图所示），它的输出层为block3, block4, block7, block8, block9_box, block10，每个输出层输出不同尺度[(64, 64), (32, 32), (16, 16), (8, 8), (4, 4), (2, 2)]的特征图, 它们负责检测不同尺度的物体。根据实验预设可知，每个输出层的每个区域使用的anchor数量分别为4，4，6，6，6，4，且每个anchor的检测类别数为目标物和背景两类。
![Picture2.png](https://i.loli.net/2019/07/22/5d3584edddf9e49336.png)

模型数据的后处理，指的就是对这些模型输出数据的处理过程。



在模型`/lab_02/nets/ssd_KYnet_v3_6b.py`中，我们将每一个输出层得到的特征图分别送入两个不同的卷积`conv_loc`和`pred_loc`中，得到分别负责推断目标的位置信息`loc_pred`和类别信息`cls_pred`的两个新特征图，用于产生预测框信息。（可见`ssd_KYnet_v3_6b.py`的402至414行）



接下来在Runner程序中，我们在`/lab_04/lab_04.2/object-detection/image_processor.cc`的`init_loc_cls()`函数中，根据输出层的节点名称来获取模型输出的`loc_pred`和`cls_pred`两个特征图，并初始化生成`cls`和`loc`两个数组。（`init_loc_cls()`函数定义可见`image_processor.cc` 的233行）



在得到`cls`和`loc`两个数组后，我们可以对`cls`和`loc`进行排序，并从`loc`恢复出每个框的四个坐标，之后便可以使用NMS进行多余框的过滤。



#### 3.2.2 NMS介绍

目标检测算法通常会输出很多检测框的结果，这些结果中有很多是冗余的，即有些框之间重叠区域很大因此可以进行合并。我们使用了一种叫非极大抑制(NMS, Non-Maximun Suppression)的算法消除了多次检测结果的干扰。NMS的目的就是要去除冗余的检测框，保留最好的一个。NMS实现的效果如下图：

<img src="https://i.loli.net/2018/12/08/5c0bd7fd9d8d6.png" style="zoom:75%" />



其原理如下：

1. 将所有框按照置信度从大到小排序，选中其中最高分值对应的框
2. 遍历剩余的框，计算每个框与第一步选中框的IOU，如果大于一定阈值，将当前框删除
3. 从剩余框中选出置信度最高的框，重复上述过程

```shell

# NMS算法伪码

for i in n:

	for j in i+1 … n:
	
		If IOU(box[i], box[j])>threshold
		
			Delete box[j];
			
```



IOU计算（Intersection over Union），计算两个框之间的交叠率。

<img src="https://i.loli.net/2018/12/08/5c0be1960c291.png" style="zoom:50%" />

```python

iou = interArea / (boxAArea + boxBArea - interArea)

# interArea 为两个方框交错的面积
# boxAArea + boxBArea 为两个方框的面积和

```



本次实验的图像后处理通过`post_op()`函数实现，具体可参见`image_processor.cc`中第172行至204行。







## 4. `Runner`编译方法

`/lab_04/lab_04.2/object-detection`中，我们提供了对应的`CMakeList.txt`，以生成相应的makefile进行编译。



编译的过程非常简单，进入docker之后，执行以下操作以编译成可执行文件：

```shell

mkdir build

cd build

cmake ..

make

```







## 5.练习

### 5.1 图像预处理的实现

在`/lab_04/lab_04.2/object-detection/image_processor.cc`文件中的第163行起完成推演图片的预处理。要求如下：
1. 由于cv::Mat读入的图片默认为BGR格式，因此需要调整通道顺序，将BGR格式转换为RGB格式
2. 对每个通道进行减mean操作，每个通道中的每个像素对应需要减去的mean值可见第155行向量`mean_val`
3. 返回的data是一个一维数组，按RGB的顺序排列



### 5.2 数据后处理

在`/lab_04/lab_04.2/object-detection/third_party/libssd/post_process.cc`文件中第31行起，完成`PostProcess()`函数核心功能的实现。`PostProcess()`函数核心功能如下：
1. 遍历每个层的所有anchor，获得每个anchor的中心坐标和宽高，center_y, center_x, h, w
2. 使用anchor 将网络输出的坐标偏移换算回推断框的中心坐标和高宽
3. 以（2）中的中心坐标和高宽为输入，使用NMS过滤多余的推断框
4. 最后返回一个向量，向量内容为bbox，其中`bbox`的定义见`/lab_04/lab_04.2/object-detection/third_party/libssd/bbox.hh`



### 5.3 模型部署

**按第四节《Runner编译方法》中的步骤，在docker中实现Runner的编译，并编译得到可执行文件。**



至此，我们通过实验已经得到了执行模型的可执行文件、模型结构文件（.pbtxt）、量化过的模型参数文件（coeff_little），加上预先提供的板卡参数定义文件（*_config.txt），我们便具备了模型部署的所需的所有文件。



为了方便，我们需要将这些文件统一放入一个文件夹（如`./ssd`）

```shell

#进入板卡中的deployment文件夹
cd ssd

```

之后，输入如下命令，执行模型加速，并观察输出结果。

```shell

./image_object_detection \							#执行可执行文件

  --sg ./ssd_opt_sg.pbtxt \							#模型结构文件
  
  --images ../fddb/testing-data/ \					#测试图片
  
  --data ./ssd_quant_coeff/coeff_little/ \			#模型参数
  
  --processor ssd \
  
  --batch 1 \
  
  --group 1000 \
  
  --num_threads 2 \
  
  --image_list ../references/fddblist.txt \
  
  --output_file ../predictions.txt \
  
  --from_file=true \
  
  --config_file ../ssd_config.txt \					#SSD后处理配置文件
  
  --param_path ./poat_param/ \						#后处理（anchor）参数
  
  --with_image_output=true
	
```





